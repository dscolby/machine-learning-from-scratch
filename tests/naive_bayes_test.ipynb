{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4bf12a",
   "metadata": {},
   "source": [
    "# Naive Bayes Test\n",
    "#### Author: Darren Colby\n",
    "#### Date: March 18th, 2022\n",
    "### Purpose: To test the functionality of the NaiveBayes class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a9eaf",
   "metadata": {},
   "source": [
    "## Setting up the notebook for subsequent questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f70182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from NaiveBayes import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b98a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "naive = np.loadtxt(\"hw4_naive.csv\", delimiter = \",\", skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f8eefe",
   "metadata": {},
   "source": [
    "### Create the train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3446fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features and labels\n",
    "x = naive[:, :-1]\n",
    "y = naive[:, -1]\n",
    "\n",
    "# Create train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb43676",
   "metadata": {},
   "source": [
    "### Fitting the model\n",
    "The first step here is fitting our model. Unlike other supervised learning methods that rely on gradient descent to learn some weights that minimize a cost function, Naive Bayes is a probabilistic model. This means the only thing we need to do in this step is calculate the priors for each class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f37393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a multinomial pdf\n",
    "multinomial = NaiveBayes()\n",
    "\n",
    "# Fit the model\n",
    "multinomial.fit(y_train)\n",
    "\n",
    "# Get predictions and posteriors\n",
    "multinomial_predictions, multinomial_posteriors = multinomial.predict(x_train, y_train, x_test, 'multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9166b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a gaussian pdf\n",
    "gaussian = NaiveBayes()\n",
    "\n",
    "# Fit the model\n",
    "gaussian.fit(y_train)\n",
    "\n",
    "# Get predictions and posteriors\n",
    "gaussian_predictions, gaussian_posteriors = gaussian.predict(x_train, y_train, x_test, 'gaussian')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01352874",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "No matter how complicated a model is, if it does not perform well, there is no sense in using it. Therfore, it would be useful to know some metrics like the number of true positives, true negatives, false positives, false negatives, accuracy, precision, recall, and F1 score, which the function below calculates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd06ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_actual, y_pred):\n",
    "    \"\"\"Calculates true positives, true negatives, false positives, false negatives, accuracy, precision, recall, and F1 score\n",
    "       ----------------------------------------------------------------------------------------------------------------------\n",
    "       \n",
    "       Parameters:\n",
    "            y_actual: actual labels\n",
    "            y_pred: predicted labels\n",
    "            \n",
    "       Returns a tuple of the true positives, true negatives, false positives, false negatives, accuracy, precision, recall, \n",
    "           and F1 score\"\"\"\n",
    "    \n",
    "    # Store the class labels\n",
    "    labels = np.unique(y_actual)\n",
    "    \n",
    "    # When there are only two class labels\n",
    "    if y_actual.size == 2:\n",
    "        \n",
    "        # Calculate positives and negatives\n",
    "        true_positive = np.sum(np.where((y_pred == 1) & (y_actual == 1)))\n",
    "        true_negative = np.sum(np.where((y_pred == 0) & (y_actual == 0)))\n",
    "        false_positive = np.sum(np.where((y_pred == 1) & (y_actual == 0)))\n",
    "        false_negative = np.sum(np.where((y_pred == 0) & (y_actual == 1)))\n",
    "    \n",
    "    # When doing multiclass classification\n",
    "    else:\n",
    "        \n",
    "        for label in labels:\n",
    "        \n",
    "            # Calculate positives and negatives\n",
    "            true_positive = np.sum(np.where((y_pred == label) & (y_actual == label)))\n",
    "            true_negative = np.sum(np.where((y_pred != label) & (y_actual != label)))\n",
    "            false_positive = np.sum(np.where((y_pred == label) & (y_actual != label)))\n",
    "            false_negative = np.sum(np.where((y_pred != label) & (y_actual == label)))\n",
    "            \n",
    "    # Calculate accuracy\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    \n",
    "    # Calculate the F1 score\n",
    "    f1 = (2 * (precision * recall)) / (precision + recall)\n",
    "        \n",
    "    return true_positive, true_negative, false_positive, false_negative, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e78b7",
   "metadata": {},
   "source": [
    "### Using the model\n",
    "Now it is time to use the model. In the first cell, we assume a multinomial distribution to train, predict, ad evaluate our model. The second cell assumes a gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e98617e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 score with a multiomial distribution is 0.8505722541329463\n"
     ]
    }
   ],
   "source": [
    "# Multinomial distribution\n",
    "\n",
    "# Evaluate\n",
    "multinomial_evaluations = evaluate(y_test, multinomial_predictions)\n",
    "print(\"The F1 score with a multiomial distribution is \" + str(multinomial_evaluations[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d246a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 score with a Gaussian distribution is 0.31365711284270037\n"
     ]
    }
   ],
   "source": [
    "# Gaussian distribution\n",
    "\n",
    "# Evaluate\n",
    "gaussian_evaluations = evaluate(y_test, gaussian_predictions)\n",
    "print(\"The F1 score with a Gaussian distribution is \" + str(gaussian_evaluations[7]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
